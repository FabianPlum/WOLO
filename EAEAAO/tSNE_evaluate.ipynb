{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SO \n",
    "Here is how I'm gonna do this\n",
    "as a first try, without any preprocessing, simply combine all the data into a single\n",
    "dataframe, regardless of threshold, just to nail down how the data needs to be structured\n",
    "\n",
    "one by one, read in the csv files, creating one line in the data frame for every 30 frames\n",
    "then write the identity in terms of video, bramble-or-rose, startframe, id, extracted body-length, as the \n",
    "first 5 elements in the row. The 6th entry is then the size class, so we can use that as a\n",
    "label. without any smoothing, angles, or speeds, the shape of the data-frame will then be\n",
    "\n",
    "(n, 30 * num_key_points + 6)\n",
    "\n",
    "to run dimensionality reduction on that data, simply repeat the setup above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from umap import UMAP\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"I:/WOLO/WOLO/EAEAAO/EXTRACTED_POSE_FEATURE_VECTORS\"\n",
    "df_ant_poses_list =  [os.path.join(input_folder,f) for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f))]\n",
    "\n",
    "df_ant_poses_dfs = [pd.read_pickle(filename) for filename in df_ant_poses_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the DataFrames\n",
    "df_ant_poses = pd.concat(df_ant_poses_dfs, ignore_index=True, axis=0)\n",
    "\n",
    "features = df_ant_poses.loc[:, 'raw_pose_0':] # use all entries and exclude labels\n",
    "labels =  df_ant_poses.loc[:, :\"size_class\"]\n",
    "\n",
    "norm_features = (features-features.min())/(features.max()-features.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"extracted feature vector contains\",norm_features.shape[0],\"instances and\", norm_features.shape[1], \"features\")\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a test, run a 2D tSNE\n",
    "tsne = TSNE(n_components=2, random_state=0, init=\"pca\", learning_rate=\"auto\", perplexity=50)\n",
    "projections = tsne.fit_transform(norm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections_and_labels = labels.copy()\n",
    "projections_and_labels[\"x\"] = projections[:,0]\n",
    "projections_and_labels[\"y\"] = projections[:,1]\n",
    "\n",
    "projections_and_labels.to_pickle(\"tSNE_perplexity_50\")\n",
    "\n",
    "# now take the produced embedding and plot with different colour overlays to group by class, speed, or material\n",
    "fig_size = px.scatter(\n",
    "    projections_and_labels, x=\"x\", y=\"y\",\n",
    "    color=\"size_class\", labels={'color': 'size_class'},\n",
    "    opacity=0.1,\n",
    "    hover_name=\"video\", hover_data=[\"material\",\"startframe\",\"id\",\"speed\",\"size_class\"],\n",
    "    width=600, height=500) \n",
    "\n",
    "fig_size.write_image(\"tSNE_fig_size.svg\")\n",
    "fig_size.write_html(\"tSNE_fig_size.html\")\n",
    "\n",
    "fig_speed = px.scatter(\n",
    "    projections_and_labels, x=\"x\", y=\"y\",\n",
    "    color=\"speed\", labels={'color': 'speed'},\n",
    "    hover_name=\"video\", hover_data=[\"material\",\"startframe\",\"id\",\"speed\",\"size_class\"],\n",
    "    range_color=(0,50),\n",
    "    opacity=0.1,\n",
    "    width=600, height=500) \n",
    "\n",
    "fig_speed.write_image(\"tSNE_fig_speed.svg\")\n",
    "fig_speed.write_html(\"tSNE_fig_speed.html\")\n",
    "\n",
    "fig_material = px.scatter(\n",
    "    projections_and_labels, x=\"x\", y=\"y\",\n",
    "    color=\"material\", labels={'color': 'material'},\n",
    "    hover_name=\"video\", hover_data=[\"material\",\"startframe\",\"id\",\"speed\",\"size_class\"],\n",
    "    opacity=0.1,\n",
    "    width=600, height=500) \n",
    "\n",
    "fig_material.write_image(\"tSNE_fig_material.svg\")\n",
    "fig_material.write_html(\"tSNE_fig_material.html\")\n",
    "\n",
    "fig_size.show()\n",
    "fig_speed.show()\n",
    "fig_material.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_2d = UMAP(n_components=2, init='pca')#, random_state=0)\n",
    "proj_2d = umap_2d.fit_transform(norm_features)\n",
    "\n",
    "projections_and_labels_UMAP = labels.loc[200000:300000,:].copy()\n",
    "projections_and_labels_UMAP[\"x\"] = proj_2d[:,0]\n",
    "projections_and_labels_UMAP[\"y\"] = proj_2d[:,1]\n",
    "\n",
    "projections_and_labels_UMAP.to_pickle(\"UMAP_df\")\n",
    "\n",
    "fig_size_2d = px.scatter(\n",
    "    projections_and_labels_UMAP, x=\"x\", y=\"y\",\n",
    "    color=\"size_class\", labels={'color': 'size_class'},\n",
    "    opacity=0.1,\n",
    "    hover_name=\"video\", hover_data=[\"material\",\"startframe\",\"id\",\"speed\",\"size_class\"],\n",
    "    width=600, height=500) \n",
    "\n",
    "fig_speed_2d = px.scatter(\n",
    "    projections_and_labels_UMAP, x=\"x\", y=\"y\",\n",
    "    color=\"speed\", labels={'color': 'speed'},\n",
    "    hover_name=\"video\", hover_data=[\"material\",\"startframe\",\"id\",\"speed\",\"size_class\"],\n",
    "    opacity=0.1,\n",
    "    range_color=(0,50),\n",
    "    width=600, height=500) \n",
    "\n",
    "fig_material_2d = px.scatter(\n",
    "    projections_and_labels_UMAP, x=\"x\", y=\"y\",\n",
    "    color=\"material\", labels={'color': 'material'},\n",
    "    hover_name=\"video\", hover_data=[\"material\",\"startframe\",\"id\",\"speed\",\"size_class\"],\n",
    "    opacity=0.1,\n",
    "    width=600, height=500) \n",
    "\n",
    "fig_size_2d.show()\n",
    "fig_speed_2d.show()\n",
    "fig_material_2d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load produced embeddings for further analysis (such as hdbscan clustering) and re-plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_loc = \"Z:/home/EAEAAO/UMAP_2D_mean-normalisation/UMAP_df\"\n",
    "projections_and_labels_UMAP = pd.read_pickle(embedding_loc)\n",
    "\n",
    "fig_size_2d = px.scatter(\n",
    "    projections_and_labels_UMAP, x=\"x\", y=\"y\",\n",
    "    color=\"size_class\", labels={'color': 'size_class'},\n",
    "    opacity=0.01,\n",
    "    hover_name=\"video\", hover_data=[\"material\",\"startframe\",\"id\",\"speed\",\"size_class\"],\n",
    "    width=1000, height=800) \n",
    "\n",
    "fig_size_2d.write_image(\"UMAP_fig_size.svg\")\n",
    "fig_size_2d.write_html(\"UMAP_fig_size.html\")\n",
    "\n",
    "fig_speed_2d = px.scatter(\n",
    "    projections_and_labels_UMAP, x=\"x\", y=\"y\",\n",
    "    color=\"speed\", labels={'color': 'speed'},\n",
    "    hover_name=\"video\", hover_data=[\"material\",\"startframe\",\"id\",\"speed\",\"size_class\"],\n",
    "    opacity=0.01,\n",
    "    range_color=(0,50),\n",
    "    width=1000, height=800) \n",
    "\n",
    "fig_speed_2d.write_image(\"UMAP_fig_speed.svg\")\n",
    "fig_speed_2d.write_html(\"UMAP_fig_speed.html\")\n",
    "\n",
    "fig_material_2d = px.scatter(\n",
    "    projections_and_labels_UMAP, x=\"x\", y=\"y\",\n",
    "    color=\"material\", labels={'color': 'material'},\n",
    "    hover_name=\"video\", hover_data=[\"material\",\"startframe\",\"id\",\"speed\",\"size_class\"],\n",
    "    opacity=0.01,\n",
    "    width=1000, height=800) \n",
    "\n",
    "fig_material_2d.write_image(\"UMAP_fig_material.svg\")\n",
    "fig_material_2d.write_html(\"UMAP_fig_material.html\")\n",
    "\n",
    "#fig_size_2d.show()\n",
    "#fig_speed_2d.show()\n",
    "#fig_material_2d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "import numpy as np\n",
    "clusterable_embedding = projections_and_labels_UMAP.loc[:,\"x\":\"y\"]\n",
    "\n",
    "labels = hdbscan.HDBSCAN(\n",
    "    min_samples=100,\n",
    "    min_cluster_size=1000,\n",
    "    cluster_selection_epsilon=0.03,\n",
    "    alpha = 0.5,\n",
    "    cluster_selection_method=\"leaf\"\n",
    ").fit_predict(clusterable_embedding)\n",
    "\n",
    "print(\"Datapoints assigned to clusters:\",len(labels[clustered]))\n",
    "print(\"Datapoints unassigned:\",len(labels[~clustered]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_embedding = projections_and_labels_UMAP.loc[:,\"x\":\"y\"].to_numpy()\n",
    "\n",
    "clustered = (labels >= 0)\n",
    "plt.scatter(standard_embedding[~clustered, 0],\n",
    "            standard_embedding[~clustered, 1],\n",
    "            color=(0.5, 0.5, 0.5),\n",
    "            s=0.1,\n",
    "            alpha=0.5)\n",
    "plt.scatter(standard_embedding[clustered, 0],\n",
    "            standard_embedding[clustered, 1],\n",
    "            c=labels[clustered],\n",
    "            s=0.1,\n",
    "            cmap='Spectral');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_class_2d = px.scatter(\n",
    "    projections_and_labels_UMAP.loc[clustered,:], x=\"x\", y=\"y\",\n",
    "    color=labels[clustered], labels={'color': \"cluster\"},\n",
    "    opacity=0.1,\n",
    "    hover_name=\"video\", hover_data=[\"material\",\"startframe\",\"id\",\"speed\",\"size_class\"],\n",
    "    width=1000, height=800) \n",
    "\n",
    "fig_class_2d.write_image(\"UMAP_fig_class.svg\")\n",
    "fig_class_2d.write_html(\"UMAP_fig_class.html\")\n",
    "\n",
    "#fig_class_2d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_non_class_2d = px.scatter(\n",
    "    projections_and_labels_UMAP.loc[~clustered,:], x=\"x\", y=\"y\",\n",
    "    opacity=0.01, \n",
    "    hover_name=\"video\", hover_data=[\"material\",\"startframe\",\"id\",\"speed\",\"size_class\"],\n",
    "    width=1000, height=800) \n",
    "\n",
    "fig_non_class_2d.write_image(\"UMAP_fig_unassigned.svg\")\n",
    "fig_non_class_2d.write_html(\"UMAP_fig_unassigned.html\")\n",
    "\n",
    "#fig_non_class_2d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2176\n",
    "2904\n",
    "274\n",
    "\n",
    "at_frame = 156978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections_and_labels_UMAP[projections_and_labels_UMAP.id == 2176][projections_and_labels_UMAP.startframe > at_frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections_and_labels_UMAP[projections_and_labels_UMAP.id == 2904][projections_and_labels_UMAP.startframe > at_frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections_and_labels_UMAP[projections_and_labels_UMAP.id == 274][projections_and_labels_UMAP.startframe > at_frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot clusters for specific materials\n",
    "\n",
    "fig_bramble_2d = px.scatter(\n",
    "    projections_and_labels_UMAP[projections_and_labels_UMAP.material==\"bramble\"], x=\"x\", y=\"y\",\n",
    "    opacity=0.1,\n",
    "    hover_name=\"video\", hover_data=[\"material\",\"startframe\",\"id\",\"speed\",\"size_class\"],\n",
    "    width=1000, height=800) \n",
    "\n",
    "fig_bramble_2d.write_image(\"UMAP_fig_bramble.svg\")\n",
    "fig_bramble_2d.write_html(\"UMAP_fig_bramble.html\")\n",
    "\n",
    "fig_rose_2d = px.scatter(\n",
    "    projections_and_labels_UMAP[projections_and_labels_UMAP.material==\"rose\"], x=\"x\", y=\"y\",\n",
    "    hover_name=\"video\", hover_data=[\"material\",\"startframe\",\"id\",\"speed\",\"size_class\"],\n",
    "    opacity=0.1,\n",
    "    range_color=(0,50),\n",
    "    width=1000, height=800) \n",
    "\n",
    "fig_rose_2d.write_image(\"UMAP_fig_rose.svg\")\n",
    "fig_rose_2d.write_html(\"UMAP_fig_rose.html\")\n",
    "\n",
    "#fig_rose_2d.show()\n",
    "#fig_bramble_2d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size_2d.update_xaxes(range=[5, 10])\n",
    "fig_size_2d.update_yaxes(range=[-2, 4])\n",
    "\n",
    "fig_size_2d.write_image(\"UMAP_fig_size_cropped.svg\")\n",
    "\n",
    "fig_speed_2d.update_xaxes(range=[5, 10])\n",
    "fig_speed_2d.update_yaxes(range=[-2, 4])\n",
    "\n",
    "fig_speed_2d.write_image(\"UMAP_fig_speed_cropped.svg\")\n",
    "\n",
    "fig_material_2d.update_xaxes(range=[5, 10])\n",
    "fig_material_2d.update_yaxes(range=[-2, 4])\n",
    "\n",
    "fig_material_2d.write_image(\"UMAP_fig_material_cropped.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
